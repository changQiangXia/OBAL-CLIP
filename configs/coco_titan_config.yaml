# RTX 3080 Ti (12GB) TITAN 配置
# 警告：batch_size 128，接近 12GB 极限，可能轻微 OOM
# 如果失败，请用 omega 配置 (batch 96)

experiment_name: "the_architect_coco_titan"
seed: 42
debug: false

# Model Configuration
model:
  name: "the_architect"
  clip_model: "ViT-B-32"
  clip_pretrained: "openai"
  
  detector:
    type: "yolov8"
    model_name: "yolov8n.pt"
    conf_threshold: 0.3
    max_detections: 10
    device: "cuda"
  
  # 超大 Adapter
  adapter:
    hidden_dim: 1536
    num_heads: 16
    num_layers: 12
    dropout: 0.1
    use_lora: false
    freeze_clip: true

# Training Configuration
training:
  num_epochs: 20
  batch_size: 128      # 极限 batch size，118K/128=924 步/epoch
  gradient_accumulation_steps: 1
  
  optimizer:
    type: "adamw"
    lr: 6.0e-4         # 配合 batch 128 的大学习率
    weight_decay: 0.01
    betas: [0.9, 0.98]
  
  scheduler:
    type: "cosine"
    warmup_steps: 3500
    min_lr: 1.0e-6
  
  amp: true
  clip_grad_norm: 1.0
  save_every: 5
  eval_every: 2
  keep_last_n: 3

# Loss Configuration
loss:
  contrastive_weight: 1.0
  structural_weight: 0.5
  temperature: 0.07
  hard_negative_ratio: 1.0

# Data Configuration
data:
  use_synthetic: false
  train_datasets:
    - name: "coco"
      root: "data/coco"
      split: "train"
  eval_datasets:
    - name: "coco"
      root: "data/coco"
      split: "val"
  
  image_size: 224
  num_workers: 8
  pin_memory: true
  persistent_workers: true
  prefetch_factor: 4
  
  augmentation:
    random_crop: true
    random_flip: true
    color_jitter: 0.2

visualization:
  enabled: false
  plot_every: 1000
  save_attention_maps: false
  save_qualitative: false
  num_qualitative_samples: 0

logging:
  level: "INFO"
  use_tensorboard: true
  use_wandb: false
  log_every: 100

device: "auto"
