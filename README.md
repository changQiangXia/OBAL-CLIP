# The Architect

åŸºäº CLIP æ”¹è¿›çš„å¤šæ¨¡æ€æ¨¡å‹ï¼Œä¸“æ³¨äºè§£å†³**å¤šå¯¹è±¡å±æ€§ç»‘å®šé—®é¢˜**ï¼ˆMulti-Object Attribute Bindingï¼‰ï¼Œä¾‹å¦‚å‡†ç¡®åŒºåˆ† "red cat and blue dog" ä¸ "blue cat and red dog"ã€‚

[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![PyTorch 2.0+](https://img.shields.io/badge/pytorch-2.0+-red.svg)](https://pytorch.org/)
[![License](https://img.shields.io/badge/license-MIT-green.svg)](LICENSE)

## ğŸ“Š å®éªŒç»“æœ

åœ¨ **SugarCrepe** åŸºå‡†æµ‹è¯•ä¸Šå–å¾—ä¼˜å¼‚è¡¨ç°ï¼š

| ä»»åŠ¡ | å‡†ç¡®ç‡ | ç›¸æ¯” CLIP æå‡ |
|------|--------|---------------|
| **Overall** | **80.95%** | **+20.9%** |
| Swap-Attribute | 68.32% | +10.3% |
| Swap-Object | 66.53% | +4.5% |
| Replace-Attribute | 83.50% | +18.5% |
| **Replace-Object** | **92.92%** | **+27.9%** |
| Replace-Relation | 73.97% | +19.0% |

> SugarCrepe æ˜¯ç»„åˆæ€§ç†è§£çš„æƒå¨åŸºå‡†ï¼ŒåŒ…å« 4,757 ä¸ªæµ‹è¯•æ ·æœ¬ï¼Œè¦†ç›–å±æ€§äº¤æ¢ã€å¯¹è±¡æ›¿æ¢ã€å…³ç³»æ›¿æ¢ç­‰å¤šç§åœºæ™¯ã€‚

### å¯è§†åŒ–ç»“æœ

**å„å­é›†å‡†ç¡®ç‡å¯¹æ¯”**
![Accuracy Comparison](outputs/visualizations/sugarcrepe_accuracy_comparison.png)

**ä¸ CLIP Baseline å¯¹æ¯”**
![Baseline Comparison](outputs/visualizations/baseline_comparison.png)

**äº”ç»´èƒ½åŠ›é›·è¾¾å›¾**
![Capability Radar](outputs/visualizations/capability_radar.png)

**é”™è¯¯æ¡ˆä¾‹åˆ†æ**
![Error Analysis](outputs/visualizations/error_analysis.png)

---

## ğŸ—ï¸ æ ¸å¿ƒç‰¹æ€§

- ğŸ” **Object-Aware Adapter**: åœ¨å†»ç»“çš„ CLIP è§†è§‰ç¼–ç å™¨åå¼•å…¥ç‰©ä½“æ„ŸçŸ¥é€‚é…å™¨
- ğŸ¯ **Cross-Attention èåˆ**: åˆ©ç”¨ç‰©ä½“æ£€æµ‹å™¨æå–åŒºåŸŸç‰¹å¾ï¼Œä¸å…¨å±€ç‰¹å¾èåˆ
- ğŸ’¡ **Structural Loss**: åˆ›æ–°çš„æŸå¤±å‡½æ•°ï¼Œä¸“é—¨æƒ©ç½šå±æ€§ä¸å®ä½“çš„é”™è¯¯ç»‘å®š
- â›ï¸ **Hard Negative Mining**: è‡ªåŠ¨ç”Ÿæˆç¡¬è´Ÿæ ·æœ¬ï¼Œå¦‚å°†"çº¢çŒ«è“ç‹—"å˜ä¸º"çº¢ç‹—è“çŒ«"

---

## ğŸ“ é¡¹ç›®ç»“æ„

```
.
â”œâ”€â”€ src/                    # æºä»£ç 
â”‚   â”œâ”€â”€ models/             # æ¨¡å‹æ¶æ„
â”‚   â”‚   â”œâ”€â”€ adapter.py      # ObjectAwareAdapter
â”‚   â”‚   â”œâ”€â”€ the_architect.py # å®Œæ•´æ¨¡å‹
â”‚   â”‚   â”œâ”€â”€ detector_wrapper.py  # æ£€æµ‹å™¨åŒ…è£…å™¨
â”‚   â”‚   â””â”€â”€ model_loader.py # æ¨¡å‹åŠ è½½å·¥å…·
â”‚   â”œâ”€â”€ data/               # æ•°æ®åŠ è½½ä¸å¤„ç†
â”‚   â”‚   â””â”€â”€ dataset.py      # COCO/Synthetic Dataset
â”‚   â”œâ”€â”€ losses/             # æŸå¤±å‡½æ•°
â”‚   â”‚   â””â”€â”€ structural_loss.py  # Structural + Contrastive Loss
â”‚   â””â”€â”€ utils/              # å·¥å…·å‡½æ•°
â”‚       â””â”€â”€ visualization.py # å¯è§†åŒ–å·¥å…·
â”œâ”€â”€ configs/                # é…ç½®æ–‡ä»¶
â”‚   â”œâ”€â”€ debug_config.yaml   # RTX 3050Ti (4GB) è°ƒè¯•é…ç½®
â”‚   â”œâ”€â”€ coco_godlike_config.yaml  # RTX 3080 Ti (12GB) é«˜æ€§èƒ½é…ç½®
â”‚   â””â”€â”€ train_config.yaml   # RTX 4090 (24GB) å…¨é‡é…ç½®
â”œâ”€â”€ scripts/                # è®­ç»ƒ/è¯„ä¼°è„šæœ¬
â”‚   â”œâ”€â”€ train.py            # è®­ç»ƒè„šæœ¬
â”‚   â”œâ”€â”€ evaluate.py         # åŸºç¡€è¯„ä¼°
â”‚   â”œâ”€â”€ eval_sugarcrepe.py  # SugarCrepe åŸºå‡†è¯„ä¼°
â”‚   â”œâ”€â”€ generate_report.py  # ç”Ÿæˆå¯è§†åŒ–æŠ¥å‘Š
â”‚   â””â”€â”€ download_aro.py     # æ•°æ®é›†ä¸‹è½½
â”œâ”€â”€ notebooks/              # å¯è§†åŒ–ä¸åˆ†æ
â”œâ”€â”€ docs/                   # æ–‡æ¡£
â”‚   â”œâ”€â”€ RISK_ANALYSIS.md    # é£é™©åˆ†æ
â”‚   â””â”€â”€ DATASET_GUIDE.md    # æ•°æ®é›†æŒ‡å—
â”œâ”€â”€ data/                   # æ•°æ®é›†ç›®å½•
â”‚   â”œâ”€â”€ coco/               # COCO æ•°æ®é›†
â”‚   â””â”€â”€ sugarcrepe/         # SugarCrepe è¯„ä¼°æ•°æ®
â”œâ”€â”€ outputs/                # è¾“å‡ºç›®å½•
â”‚   â”œâ”€â”€ checkpoints/        # æ¨¡å‹æ£€æŸ¥ç‚¹
â”‚   â”œâ”€â”€ visualizations/     # å¯è§†åŒ–å›¾è¡¨
â”‚   â””â”€â”€ latex/              # LaTeX è¡¨æ ¼
â””â”€â”€ logs/                   # æ—¥å¿—ç›®å½•
```

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### ç¯å¢ƒè¦æ±‚

- **Python**: 3.10+
- **CUDA**: 11.8+ (æ¨è)
- **GPU**: 
  - æœ€å°: 4GB VRAM (RTX 3050Ti, ä»…æ”¯æŒè°ƒè¯•æ¨¡å¼)
  - æ¨è: 12GB+ VRAM (RTX 3080 Ti/4070)
  - æœ€ä½³: 24GB VRAM (RTX 4090/A5000)

### å®‰è£…æ­¥éª¤

```bash
# å…‹éš†ä»“åº“
git clone <repository-url>
cd the-architect

# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
conda create -n architect python=3.10
conda activate architect

# å®‰è£…ä¾èµ–
pip install -r requirements.txt

# ä¸‹è½½ YOLOv8 é¢„è®­ç»ƒæƒé‡ï¼ˆé¦–æ¬¡è¿è¡Œè‡ªåŠ¨ä¸‹è½½ï¼‰
# æˆ–æ‰‹åŠ¨ä¸‹è½½: wget https://github.com/ultralytics/assets/releases/download/v8.0.0/yolov8n.pt
```

---

## ğŸ’¾ æ•°æ®å‡†å¤‡

### è®­ç»ƒæ•°æ®

1. **COCO 2017** (å¿…éœ€)
   ```bash
   # ä¸‹è½½å¹¶è§£å‹åˆ° data/coco/
   wget http://images.cocodataset.org/zips/train2017.zip
   wget http://images.cocodataset.org/zips/val2017.zip
   wget http://images.cocodataset.org/annotations/annotations_trainval2017.zip
   ```

2. **SugarCrepe** (è¯„ä¼°ç”¨ï¼Œå·²åŒ…å«åœ¨ä»“åº“ä¸­)
   ```bash
   # æ•°æ®å·²é¢„ç½®åœ¨ data/sugarcrepe/
   # å¦‚éœ€é‡æ–°ä¸‹è½½:
   wget https://github.com/RAIVNLab/sugarcrepe/raw/main/data/swap_att.json
   ```

---

## ğŸ‹ï¸ è®­ç»ƒ

### 1. è°ƒè¯•æ¨¡å¼ (RTX 3050Ti 4GB)

```bash
python scripts/train.py --config configs/debug_config.yaml
```

ç‰¹ç‚¹ï¼š
- Batch size: 8
- ä½¿ç”¨ DummyDetector (æ— éœ€çœŸå®æ£€æµ‹å™¨)
- æ¢¯åº¦ç´¯ç§¯: 4 steps
- é€‚åˆä»£ç è°ƒè¯•å’Œæµç¨‹éªŒè¯

### 2. é«˜æ€§èƒ½è®­ç»ƒ (RTX 3080 Ti 12GB)

```bash
python scripts/train.py --config configs/coco_godlike_config.yaml
```

ç‰¹ç‚¹ï¼š
- Batch size: 80
- 12 å±‚ Adapter
- å®Œæ•´ YOLOv8 æ£€æµ‹å™¨
- è®­ç»ƒ 20 epochs çº¦ 2-3 å°æ—¶

### 3. å…¨é‡è®­ç»ƒ (RTX 4090 24GB)

```bash
python scripts/train.py --config configs/train_config.yaml
```

ç‰¹ç‚¹ï¼š
- Batch size: 128
- æœ€å¤§æ¨¡å‹é…ç½®
- æ”¯æŒæ›´å¤šæ•°æ®å¢å¼º

### è®­ç»ƒç›‘æ§

```bash
# ä½¿ç”¨ TensorBoard
tensorboard --logdir logs/

# æˆ–ä½¿ç”¨ Weights & Biases (éœ€åœ¨é…ç½®ä¸­å¯ç”¨)
```

---

## ğŸ“Š è¯„ä¼°

### SugarCrepe åŸºå‡†æµ‹è¯• (æ¨è)

```bash
# è¯„ä¼°æ‰€æœ‰å­é›†
python scripts/eval_sugarcrepe.py \
    --config configs/coco_godlike_config.yaml \
    --checkpoint outputs/checkpoints/the_architect_coco_godlike_best.pt \
    --subset all

# ä»…è¯„ä¼°ç‰¹å®šå­é›† (å¿«é€Ÿæµ‹è¯•)
python scripts/eval_sugarcrepe.py \
    --config configs/coco_godlike_config.yaml \
    --checkpoint outputs/checkpoints/the_architect_coco_godlike_best.pt \
    --subset swap_att
```

è¯„ä¼°ç»“æœå°†ä¿å­˜è‡³ `outputs/sugarcrepe_results_all.json`

### ç”Ÿæˆå¯è§†åŒ–æŠ¥å‘Š

```bash
# ç”Ÿæˆ HTML æŠ¥å‘Š + æ‰€æœ‰å›¾è¡¨
python scripts/generate_report.py

# ç”Ÿæˆ CCF é£æ ¼ LaTeX è¡¨æ ¼
python scripts/generate_latex_table.py

# ç”Ÿæˆ PPT ç”¨å›¾
python scripts/generate_ppt_figure.py
```

ç”Ÿæˆçš„æ–‡ä»¶ï¼š
- `outputs/evaluation_report.html` - äº¤äº’å¼ HTML æŠ¥å‘Š
- `outputs/visualizations/*.png` - å„ç§å›¾è¡¨
- `outputs/latex/*.tex` - LaTeX è¡¨æ ¼ä»£ç 

---

## ğŸ¯ æ¨¡å‹æ¶æ„

### æ•´ä½“æµç¨‹

```
Input Image â”€â”€â”€â–º CLIP Visual Encoder â”€â”€â”€â–º [CLS] Token â”€â”€â”€â”€â”€â”€â”
                                                             â”‚
                                                             â”‚ Query
                                                             â–¼
Input Image â”€â”€â”€â–º Object Detector â”€â”€â”€â–º RoI Features â”€â”€â”€â–º Projection
                                                             â”‚
                                                             â”‚ Key/Value
                                                             â–¼
                                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                        â”‚   ObjectAwareAdapter        â”‚
                                        â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
                                        â”‚   â”‚ Cross-Attention Ã— L â”‚   â”‚
                                        â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
                                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                             â”‚
                                                             â–¼
                                            Enhanced Visual Feature
                                                             â”‚
                        Contrastive Learning â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                             â”‚
Input Text â”€â”€â”€â–º CLIP Text Encoder â”€â”€â”€â–º Text Feature â—„â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### æ ¸å¿ƒç»„ä»¶

#### 1. Object-Aware Adapter
- **è¾“å…¥**: CLIP [CLS] token + YOLOv8 åŒºåŸŸç‰¹å¾
- **æœºåˆ¶**: Cross-Attention (Query=CLS, Key/Value=Regions)
- **å±‚æ•°**: 4-12 å±‚ (å¯é…ç½®)
- **å‚æ•°é‡**: ~50M (12å±‚é…ç½®)

#### 2. Structural Loss
```
L_total = Î»1 * L_contrastive + Î»2 * L_structural
```

- **Contrastive Loss**: æ ‡å‡†çš„ InfoNCE
- **Structural Loss**: Triplet Loss æƒ©ç½šå±æ€§ç»‘å®šé”™è¯¯
- **Hard Negatives**: è‡ªåŠ¨ç”Ÿæˆå±æ€§äº¤æ¢/æ›¿æ¢æ ·æœ¬

---

## ğŸ”§ é…ç½®è¯´æ˜

å…³é”®é…ç½®å‚æ•° (ä½äº `configs/*.yaml`):

```yaml
model:
  clip_model: "ViT-B-32"          # CLIP å˜ä½“
  adapter:
    hidden_dim: 1536              # Adapter ç»´åº¦
    num_heads: 16                 # Attention heads
    num_layers: 12                # Adapter å±‚æ•°
  detector:
    type: "yolov8"                # æ£€æµ‹å™¨ç±»å‹
    max_detections: 10            # æœ€å¤§æ£€æµ‹ç‰©ä½“æ•°

training:
  num_epochs: 20
  batch_size: 80                  # æ ¹æ®æ˜¾å­˜è°ƒæ•´
  gradient_accumulation_steps: 1  # æ¢¯åº¦ç´¯ç§¯
  amp: true                       # æ··åˆç²¾åº¦

loss:
  contrastive_weight: 1.0
  structural_weight: 0.5          # ç»“æ„åŒ–æŸå¤±æƒé‡
  hard_negative_ratio: 1.0        # ç¡¬è´Ÿæ ·æœ¬æ¯”ä¾‹
```

---

## âš ï¸ æ³¨æ„äº‹é¡¹

### æ˜¾å­˜ä¼˜åŒ–å»ºè®®

| GPU æ˜¾å­˜ | é…ç½®å»ºè®® | Batch Size | Adapter å±‚æ•° |
|---------|---------|-----------|-------------|
| 4GB | debug_config.yaml | 8 | 2 |
| 8GB | è‡ªå®šä¹‰ | 32 | 4 |
| 12GB | coco_godlike_config.yaml | 80 | 12 |
| 24GB | train_config.yaml | 128 | 12 |

### å¸¸è§é—®é¢˜

1. **OOM (æ˜¾å­˜ä¸è¶³)**
   - å‡å° `batch_size`
   - å¢å¤§ `gradient_accumulation_steps`
   - å‡å° `model.adapter.num_layers`
   - å¯ç”¨ `amp: true`

2. **æ£€æµ‹å™¨åŠ è½½å¤±è´¥**
   - YOLOv8 ä¼šè‡ªåŠ¨ä¸‹è½½ï¼Œå¦‚å¤±è´¥è¯·æ£€æŸ¥ç½‘ç»œ
   - æˆ–ä½¿ç”¨ `configs/debug_config.yaml` (ä½¿ç”¨ DummyDetector)

3. **è®­ç»ƒä¸ç¨³å®š**
   - æ£€æŸ¥ `hard_negative_ratio` æ˜¯å¦è¿‡é«˜ (å»ºè®®ä» 0.5 å¼€å§‹)
   - ç¡®ä¿ `clip_grad_norm` å¯ç”¨ (é»˜è®¤ 1.0)

---

## ğŸ“š å¼•ç”¨

å¦‚æœæœ¬é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ©ï¼Œè¯·å¼•ç”¨ï¼š

```bibtex
@misc{the_architect_2024,
  title={The Architect: Solving Multi-Object Attribute Binding with CLIP},
  author={Senior CV Architect},
  year={2024}
}
```

---

## ğŸ“„ è®¸å¯

æœ¬é¡¹ç›®é‡‡ç”¨ MIT è®¸å¯è¯ - è¯¦è§ [LICENSE](LICENSE) æ–‡ä»¶

---

*Project "The Architect" - Solving Multi-Object Attribute Binding with CLIP*
